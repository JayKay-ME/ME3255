{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yams11/computational-mechanics/blob/summer22/HW_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e277b405",
      "metadata": {
        "id": "e277b405"
      },
      "source": [
        "> __Content modified under Creative Commons Attribution license CC-BY\n",
        "> 4.0, code under BSD 3-Clause License Â© 2020 R.C. Cooper__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "523bb44d",
      "metadata": {
        "id": "523bb44d"
      },
      "source": [
        "# Homework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5a090e54",
      "metadata": {
        "id": "5a090e54"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4483731",
      "metadata": {
        "id": "a4483731"
      },
      "source": [
        "## Problems [Part 1](./01_Cheers_Stats_Beers.md)\n",
        "\n",
        "1. Gordon Moore created an empirical prediction that the rate of\n",
        "semiconductors on a computer chip would double every two years. This\n",
        "prediction was known as Moore's law. Gordon Moore had originally only\n",
        "expected this empirical relation to hold from 1965 - 1975\n",
        "[[1](https://en.wikipedia.org/wiki/Moore%27s_law),[2](https://spectrum.ieee.org/computing/hardware/gordon-moore-the-man-whose-name-means-progress)],\n",
        "but semiconductor manufacturers were able to keep up with Moore's law\n",
        "until 2015. \n",
        "\n",
        "In the folder \"../data\" is a comma separated value (CSV) file,\n",
        "\"transistor_data.csv\" [taken from wikipedia\n",
        "01/2020](https://en.wikipedia.org/wiki/Transistor_count#Microprocessors).\n",
        "\n",
        "a. Use the `!head ../data/transistor_data.csv` command to look at\n",
        "the top of the csv. What are the headings for the columns?\n",
        "\n",
        "b. Load the csv into a pandas dataframe. How many missing values\n",
        "(`NaN`) are\n",
        "in the column with the number of transistors? What fraction are\n",
        "missing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "56781b99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "56781b99",
        "outputId": "6787f849-57ee-4117-9c12-d586e11cbb21"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3e886333c8e8>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    missing values=all_count-clean_count\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "'''a.What are the headings of the columns'''\n",
        "!head ../data/transistor_data.csv\n",
        "header=pd.read.csv('../data/transistor_data.csv',nrows=0)\n",
        "print('a. The header is:', header)\n",
        "'''b. Missing Values'''\n",
        "columns=pd.read.csv('../data/transistor_data.csv')\n",
        "trans_count=columns['MOS Transistor Count']\n",
        "all_count=len(trans_count)\n",
        "clean_count=trans_count.dropna()\n",
        "clean_count=clean_count.values\n",
        "clean_count=len(clean_count)\n",
        "missing values=all_count-clean_count\n",
        "fraction_missing_values=missing_values/all_count\n",
        "print('The number of missing values is',missing_values)\n",
        "print('The fraction of missing values is',fraction_missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a971755",
      "metadata": {
        "id": "8a971755"
      },
      "source": [
        "## Problems [Part 2](./02_Seeing_Stats.md)\n",
        "\n",
        "1. Many beers do not report the IBU of the beer because it is very\n",
        "small. You may be accidentally removing whole categories of beer from\n",
        "our dataset by removing rows that do not include the IBU measure. \n",
        "\n",
        "    a. Use the command `beers_filled = beers.fillna(0)` to clean the `beers` dataframe\n",
        "    \n",
        "    b. Repeat the steps above to recreate the plot \"Beer ABV vs. IBU mean values by style\" \n",
        "    scatter plot with `beers_filled`. What differences do you notice between the plots?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e01dad2a",
      "metadata": {
        "id": "e01dad2a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a71e2372",
      "metadata": {
        "id": "a71e2372"
      },
      "source": [
        "2. Gordon Moore created an empirical prediction that the rate of\n",
        "semiconductors on a computer chip would double every two years. This\n",
        "prediction was known as Moore's law. Gordon Moore had originally only\n",
        "expected this empirical relation to hold from 1965 - 1975\n",
        "[[1](https://en.wikipedia.org/wiki/Moore%27s_law),[2](https://spectrum.ieee.org/computing/hardware/gordon-moore-the-man-whose-name-means-progress)],\n",
        "but semiconductor manufacturers were able to keep up with Moore's law\n",
        "until 2015. \n",
        "\n",
        "    In the folder \"../data\" is a comma separated value (CSV) file, \"transistor_data.csv\" [taken from wikipedia 01/2020](https://en.wikipedia.org/wiki/Transistor_count#Microprocessors). \n",
        "    Load the csv into a pandas dataframe, it has the following headings:\n",
        "\n",
        "    |Processor| MOS transistor count| Date of Introduction|Designer|MOSprocess|Area|\n",
        "    |---|---|---|---|---|---|\n",
        "\n",
        "    a. In the years 2017, what was the average MOS transistor count? \n",
        "    Make a boxplot of the transistor count in 2017 and find the first, second and third quartiles.\n",
        "\n",
        "    b. Create a semilog y-axis scatter plot (i.e. `plt.semilogy`) for the \n",
        "    \"Date of Introduction\" vs \"MOS transistor count\". \n",
        "    Color the data according to the \"Designer\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "47758a18",
      "metadata": {
        "id": "47758a18"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157f581b",
      "metadata": {
        "id": "157f581b"
      },
      "source": [
        "## Problems [Part 3](03_Linear_Regression_with_Real_Data.md)\n",
        "\n",
        "1. There is a csv file in '../data/primary-energy-consumption-by-region.csv' that has the energy consumption of different regions of the world from 1965 until 2018 [Our world in Data](https://ourworldindata.org/energy). \n",
        "Compare the energy consumption of the United States to all of Europe. Load the data into a pandas dataframe. *Note: you can get certain rows of the data frame by specifying what you're looking for e.g. \n",
        "`EUR = dataframe[dataframe['Entity']=='Europe']` will give us all the rows from Europe's energy consumption.*\n",
        "\n",
        "    a. Plot the total energy consumption of the United States and Europe\n",
        "    \n",
        "    b. Use a linear least-squares regression to find a function for the energy consumption as a function of year\n",
        "    \n",
        "    energy consumed = $f(t) = At+B$\n",
        "    \n",
        "    c. At what year would you change split the data and use two lines like you did in the \n",
        "    land temperature anomoly? Split the data and perform two linear fits. \n",
        "    \n",
        "    d. What is your prediction for US energy use in 2025? How about European energy use in 2025?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "64a7aa62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "64a7aa62",
        "outputId": "15a5566b-a30a-4082-ad2b-c8862820d703"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5cbbb790d827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/primary-energy-consumption-by-region.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/primary-energy-consumption-by-region.csv'"
          ]
        }
      ],
      "source": [
        "energy = pd.read_csv('../data/primary-energy-consumption-by-region.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ff4f84",
      "metadata": {
        "id": "c8ff4f84"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d609ab",
      "metadata": {
        "id": "f0d609ab"
      },
      "source": [
        "2. You plotted Gordon Moore's empirical prediction that the rate of semiconductors on a computer chip would double every two years in [02_Seeing_Stats](./02_Seeing_Stats). This prediction was known as Moore's law. Gordon Moore had originally only expected this empirical relation to hold from 1965 - 1975 [[1](https://en.wikipedia.org/wiki/Moore%27s_law),[2](https://spectrum.ieee.org/computing/hardware/gordon-moore-the-man-whose-name-means-progress)], but semiconductor manufacuturers were able to keep up with Moore's law until 2015. \n",
        "\n",
        "Use a linear regression to find our own historical Moore's Law.    \n",
        "\n",
        "Use your code from [02_Seeing_Stats](./02_Seeing_Stats) to plot the semilog y-axis scatter plot \n",
        "(i.e. `plt.semilogy`) for the \"Date of Introduction\" vs \"MOS transistor count\". \n",
        "Color the data according to the \"Designer\".\n",
        "\n",
        "Create a linear regression for the data in the form of \n",
        "\n",
        "$log(transistor~count)= f(date) = A\\cdot date+B$\n",
        "\n",
        "rearranging\n",
        "\n",
        "$transistor~count= e^{f(date)} = e^B e^{A\\cdot date}$\n",
        "\n",
        "You can perform a least-squares linear regression using the following assignments\n",
        "\n",
        "$x_i=$ `dataframe['Date of Introduction'].values`\n",
        "\n",
        "and\n",
        "\n",
        "$y_i=$ as `np.log(dataframe['MOS transistor count'].values)`\n",
        "\n",
        "a. Plot your function on the semilog y-axis scatter plot\n",
        "\n",
        "b. What are the values of constants $A$ and $B$ for our Moore's law fit? How does this compare to Gordon Moore's prediction that MOS transistor count doubles every two years?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71e6a58",
      "metadata": {
        "id": "a71e6a58"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('../data/transistor_data.csv')\n",
        "data = data.dropna()\n",
        "xi=data['Date of Introduction'].values\n",
        "TC=data['MOS transistor count'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40cf477",
      "metadata": {
        "id": "c40cf477"
      },
      "source": [
        "## Problems [Part 4](04_Stats_and_Montecarlo.md)\n",
        "\n",
        "__1.__ [Buffon's needle problem](https://en.wikipedia.org/wiki/Buffon) is\n",
        "another way to estimate the value of $\\pi$ with random numbers. The goal\n",
        "in this Monte Carlo estimate of $\\pi$ is to create a ratio that is close\n",
        "to [3.1415926...](http://www.math.com/tables/constants/pi.htm) _similar\n",
        "to the example with darts points lying inside/outside a unit circle\n",
        "inside a unit square._ \n",
        "\n",
        "![Buffon's needle for parallel\n",
        "lines](https://upload.wikimedia.org/wikipedia/commons/f/f6/Buffon_needle.gif)\n",
        "\n",
        "In this Monte Carlo estimation, you only need to know two values:\n",
        "- the distance from line 0, $x = [0,~1]$\n",
        "- the orientation of the needle, $\\theta = [0,~2\\pi]$\n",
        "\n",
        "The y-location does not affect the outcome of crosses line 0 or not\n",
        "crossing line 0. \n",
        "\n",
        "__a.__ Generate 100 random `x` and `theta` values _remember_ $\\theta =\n",
        "[0,~2\\pi]$\n",
        "\n",
        "__b.__ Calculate the x locations of the 100 needle ends e.g. $x_end = x\n",
        "\\pm \\cos\\theta$ _since length is unit 1. \n",
        "\n",
        "__c.__ Use \n",
        "[`np.logical_and`](https://numpy.org/doc/stable/reference/generated/numpy.logical_and.html)\n",
        "to find the number of needles that have minimum $x_{end~min}<0$ and\n",
        "maximum $x_{end~max}>0$. The ratio\n",
        "$\\frac{x_{end~min}<0~and~x_{end~max}>0}{number~of~needles} =\n",
        "\\frac{2}{\\pi}$ _for large values of $number~of~needles$_.\n",
        "\n",
        "__2.__ Build a random walk data set with steps between $dx = dy =\n",
        "-1/2~to~1/2~m$. If 100 particles take 10 steps, calculate the number of\n",
        "particles that move further than 0.5 m. \n",
        "\n",
        "_Bonus: Can you do the work without any `for`-loops? Change the size of\n",
        "`dx` and `dy` to account for multiple particles._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6b5093",
      "metadata": {
        "id": "5f6b5093"
      },
      "outputs": [],
      "source": [
        "rng = default_rng()\n",
        "N_steps = 10\n",
        "dx = rng.random(N_steps) - 0.5\n",
        "dy = rng.random(N_steps) - 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93819e8",
      "metadata": {
        "id": "a93819e8"
      },
      "source": [
        "__3.__ 100 steel rods are going to be used to support a 1000 kg structure. The\n",
        "rods will buckle when the load in any rod exceeds the [critical buckling\n",
        "load](https://en.wikipedia.org/wiki/Euler%27s_critical_load)\n",
        "\n",
        "$P_{cr}=\\frac{\\pi^3 Er^4}{16L^2}$\n",
        "\n",
        "where E=200e9 Pa, r=0.01 m +/-0.001 m, and L is the \n",
        "length of the rods supporting the structure. Create a Monte\n",
        "Carlo model `montecarlo_buckle` that predicts \n",
        "the mean and standard deviation of the buckling load for 100\n",
        "samples with normally distributed dimensions r and L. \n",
        "\n",
        "```python\n",
        "mean_buckle_load,std_buckle_load=\\\n",
        "montecarlo_buckle(E,r_mean,r_std,L,N=100)\n",
        "```\n",
        "\n",
        "__a.__ What is the mean_buckle_load and std_buckle_load for L=5 m?\n",
        "\n",
        "__b.__ What length, L, should the beams be so that only 2.5% will \n",
        "reach the critical buckling load?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2c5c41",
      "metadata": {
        "id": "cb2c5c41"
      },
      "outputs": [],
      "source": [
        "def montecarlo_buckle(E,r_mean,r_std,L,N=100):\n",
        "    '''Generate N rods of length L with radii of r=r_mean+/-r_std\n",
        "    then calculate the mean and std of the buckling loads in for the\n",
        "    rod population holding a 1000-kg structure\n",
        "    Arguments\n",
        "    ---------\n",
        "    E: Young's modulus [note: keep units consistent]\n",
        "    r_mean: mean radius of the N rods holding the structure\n",
        "    r_std: standard deviation of the N rods holding the structure\n",
        "    L: length of the rods (or the height of the structure)\n",
        "    N: number of rods holding the structure, default is N=100 rods\n",
        "    Returns\n",
        "    -------\n",
        "    mean_buckle_load: mean buckling load of N rods under 1000*9.81/N-Newton load\n",
        "    std_buckle_load: std dev buckling load of N rods under 1000*9.81/N-Newton load\n",
        "    '''\n",
        "    \n",
        "    return mean_buckle_load, std_buckle_load"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "notebooks//ipynb,md:myst"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "HW_02.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}